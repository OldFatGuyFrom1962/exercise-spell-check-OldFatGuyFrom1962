{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the slides for our class on spelling correction. \n",
    "\n",
    "---\n",
    "\n",
    "### First Task\n",
    "The file “wsj_with_errors.txt” has a bunch of text in it. \n",
    "* Ingest this file.\n",
    "* Remove punctuation and numbers.\n",
    "* Cast to lowercase.\n",
    "* Take every word that’s not in the NLTK word corpus and write it to a file. (Moving NLTK words to lowercase is a good idea.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk.corpus \n",
    "\n",
    "#words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus \n",
    "from string import punctuation\n",
    "\n",
    "punctuation = frozenset(punctuation)  # slightly faster lookups\n",
    "\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open(\"wsj_with_errors.txt\") as infile\n",
    "#len(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of the words in \"wsj_with_errors\"\n",
    "all_wsj = set()\n",
    "\n",
    "with open(\"wsj_with_errors.txt\") as infile : \n",
    "    for idx, line in enumerate(infile) : \n",
    "        print(line) \n",
    "        if idx == 4 :\n",
    "            break                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of the words in \"wsj_with_errors\"\n",
    "all_wsj = set()\n",
    "\n",
    "with open(\"wsj_with_errors.txt\") as infile : \n",
    "    for idx, line in enumerate(infile) : \n",
    "        line = \"\".join([ch in line.strip() if ch not in punctuation])\n",
    "        \n",
    "        line = line.lower().split()\n",
    "        \n",
    "        line = [t for t in line if t.isalpha()]\n",
    "        \n",
    "        for token in line :\n",
    "            all_wsj.add(token)\n",
    "        #print(line) \n",
    "        #if idx == 4 :\n",
    "            #break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing punctuations string\n",
    "#punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    " \n",
    "# Removing punctuations in string\n",
    "# Using loop + punctuation string\n",
    "#for ele in infile:\n",
    "    #if ele in punc:\n",
    "        #infile = infile.replace(ele, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set([w.lower() for w in words]) # make them all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words = [] # create empty list to store the missing words\n",
    "\n",
    "with open(\"wsj_with_errors.txt\") as infile :\n",
    "    for idx, line in enumerate(infile) :\n",
    "        line = line.strip().split() # we're splitting on tab\n",
    "        line = [w.lower() for w in line if w.isalpha()]\n",
    "        \n",
    "        missing_words.extend([w for w in line if w not in words]) # adds error words in interatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wsj_potential_misspellings.txt\",'w') as outfile :\n",
    "    for word in set(missing_words) :  # we're taking our LIST 'missing words' as a SET\n",
    "        outfile.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Second Task\n",
    "\n",
    "* The file “big.txt” has about 1M words, mostly from Gutenberg. Now use words in this file (instead of the NLTK word corpus). \n",
    "* So, repeat the previous exercise, but this time use the 1M corpus as your comparison set. \n",
    "    * Note that this file requires similar cleaning. It has numbers and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = open(\"big.txt\",'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = set([w.lower() for w in words2]) # make them all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words2 = []\n",
    "with open(\"wsj_with_errors.txt\") as infile : \n",
    "    for idx, line in enumerate(infile) : \n",
    "        line = line.strip().split()\n",
    "        line = [w.lower() for w in line if w.isalpha()]\n",
    "        \n",
    "        missing_words2.extend([w for w in line if w not in words2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wsj_potential_misspellings.txt\",'w') as outfile :\n",
    "    for word2 in set(missing_words2) :  # we're taking our LIST 'missing words' as a SET\n",
    "        outfile.write(word2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# John's code... see recording\n",
    "big_words = set([w.lower() for w in open(\"big.txt\",'r').read().split() if w.isalpha()])\n",
    "# create a set (no duplications) split by white space, alpha only from the big.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Write a function that takes a word as input and returns every deletion. Sort them for the assertion statements to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletions(word) :\n",
    "    \n",
    "    deletions = []\n",
    "    \n",
    "    # Fill up this list with all strings that are \"word\" with a \n",
    "    # single character removed. You should have a list of length\n",
    "    # len(word)\n",
    "    for i in range(len(word)) :\n",
    "        deletions.append()\n",
    "    return(sorted(deletions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://stackoverflow.com/questions/627435/how-to-remove-an-element-from-a-list-by-index\n",
    "#  https://www.tutorialspoint.com/How-to-remove-an-element-from-a-list-by-index-in-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(deletions(\"help\")==['elp', 'hel', 'hep', 'hlp'])\n",
    "assert(deletions(\"me\")==['e','m'])\n",
    "assert(deletions(\"textmining\")==['extmining','tetmining','texmining','textining','textmiing',\n",
    "                                 'textminig','textminin','textminng','textmning','txtmining'])\n",
    "\n",
    "print(\"All assertion tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
